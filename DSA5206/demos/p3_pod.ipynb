{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper orthogonal decomposition as an analysis and compression tool\n",
    "\n",
    "In this notebook, we investigate the POD's implementation using SVD, and a simple application of mode analysis and compression of a image time-series (video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load time-series data\n",
    "\n",
    "We will consider a toy example where we apply POD to an image time-series (i.e. video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "video_path = './data/km3.mov'\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually handle the video data, we will use the `cv2` package. \n",
    "\n",
    "You can install it via\n",
    "```shell\n",
    "pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Convert the video to a numpy array of frames (grayscale) and normalize to [0, 1]\n",
    "frames = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_frame = cv2.threshold(gray_frame, 127, 255, cv2.THRESH_BINARY)\n",
    "    binary_frame = 1 - binary_frame / 255.0  # Normalize to [0, 1], and reverse to make sparse\n",
    "    frames.append(binary_frame)\n",
    "\n",
    "video_array = np.array(frames)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of `video_array` will be [num_frames, height, width]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames, height, width = video_array.shape\n",
    "video_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we convert the video data into an array for POD.\n",
    "\n",
    "This array will be of size $m \\times n$\n",
    "- $m = $ num_frames is the temporal dimension\n",
    "- $n = $ height $\\times$ width is the spatial dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = video_array.reshape(num_frames, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper orthogonal decomposition (or equivalently, SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the POD of the spatio-temporal data can be achieved simply from calling an SVD routine.\n",
    "\n",
    "Note that the size of u is quite large..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is quite sparse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(u.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we will use the sparse version of SVD, `scipy.sparse.linalg.svds` that is especially suited for such problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "num_components = 32\n",
    "\n",
    "# Compute the singular value decomposition\n",
    "v, s, w = svds(u, k=num_components, which='LM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `svds` does not return singular values in descending order, so we will sort them first and transform the singular vectors accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(-s)\n",
    "s = s[sorted_indices]\n",
    "v = v[:, sorted_indices]\n",
    "w = w[sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the singular value decay..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(s, 'o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the singular values are decaying, but there is no clear cut-off before 32 modes (other than the first mode), so we will take them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 32\n",
    "u_compressed = v[:, :r] @ np.diag(s[:r]) @ w[:r, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the first 6 spatial singular vectors (which are the spatial POD modes). What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(w[i].reshape(height, width), cmap='gray')\n",
    "    ax.set_title(f'POD mode {i}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the POD to compress the source time-series (video) as follows.\n",
    "\n",
    "Originally, the video is of size\n",
    "$$\n",
    "    u \\in \\R^{m\\times n}\n",
    "$$\n",
    "where $m$ is the number of time steps and $n$ is the number of pixels. Its size is $m\\times n$.\n",
    "\n",
    "By writing\n",
    "$$\n",
    "    u \\approx v s w^T\n",
    "$$\n",
    "where $v \\in \\R^{m\\times r}, s\\in\\R^{r}$ and $w \\in \\R^{n\\times r}$.\n",
    "The total size of this decomposition is\n",
    "$$\n",
    "    mr + r + nr = r(m+n+1) \\ll mn.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the compressed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_compressed = u_compressed.reshape(num_frames, height, width)\n",
    "video_compressed = (video_compressed > 0.25).astype(int)  # binarise to remove some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './data/video_compressed.mp4'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 30, (width, height), isColor=False)\n",
    "for frame in video_compressed:\n",
    "    frame = (frame * 255).astype(np.uint8)\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open {output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much compression did we achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = u.shape[0] * u.shape[1]\n",
    "compressed_size = v.shape[0] * v.shape[1] + s.shape[0] + w.shape[0] * w.shape[1]\n",
    "\n",
    "print(f\"Compression ratio: {compressed_size / original_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We saw here that POD (really SVD on the spatio-temporal data) can be used to \n",
    "- analyse key spatial modes\n",
    "- give a reduced representation of the dynamics\n",
    "\n",
    "Exercise:\n",
    "- try to improve the performance!\n",
    "- How should you measure performance?\n",
    "- Can you say anything about the temporal modes $v_k$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa5206_2023-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
